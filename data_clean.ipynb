{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the data\n",
    "'''normalize the nested json file and convert it to dataframe'''\n",
    "with open('/Users/yihuiwang/Documents/BeCode/My_project/Revenue Forcasting/asset/accounton_data.json','r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "# Normalizing data\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first five rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many rows and columns \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missinf value for the whole dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the companies which has not any value in revenue for all 6 years\n",
    "df_new= df.dropna(how='all',\n",
    "                    subset=['revenue.2020', 'revenue.2019','revenue.2018','revenue.2017','revenue.2016','revenue.2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many rows and columns \n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find type of legal_form, company_category, and province\n",
    "for col in df_new:\n",
    "    if len(df_new[col].unique())<100:\n",
    "        print(\"####################\"+col+\"####################\")\n",
    "        print(df[col].unique())\n",
    "        print(\"                            \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is duplicate in company name\n",
    "sum(df_new.duplicated(subset=['company_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check the correlation of the financial data with revenue per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get heatmap of financial data per year, with the revenue of year after\n",
    "year_list = [2019,2018,2017,2016,2015]\n",
    "for year in year_list:\n",
    "    year = pd.DataFrame(df_new,columns=['ebit.'+str(year),'ebitda.'+str(year), 'profit_and_loss_after_taxes.'+str(year), 'total_assets.'+str(year),\n",
    "'total_liabilities.'+str(year),'operating_profit_and_loss.'+str(year),'financial_profit_and_loss.'+str(year),\n",
    "'staff_count.'+str(year),'net_added_value.'+str(year),'staff_costs.'+str(year),'revenue.'+str(year+1)])\n",
    "    corrMatrix = year.corr()\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Select the Feature and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some of non_numeric columns, keep only nace_code,vat_number,company_category, province \n",
    "df_clean = df_new.drop(df_new.columns[[0,3,4,5,6]], axis=1)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missinf value after drop\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as shown in the correlation table, ebit=operating_profit_and_loss, drop it and keep only ebit,also drop ebitda\n",
    "#total_assets=total_liability, drop it and keep only total_assets\n",
    "#drop also columns of profit_and_loss_after_taxes and financial_profit_and_loss for their poor correlation\n",
    "year_list = [2020,2019,2018,2017,2016,2015]\n",
    "for year in year_list:\n",
    "    df_clean = df_clean.drop(columns=['ebitda.'+str(year),'total_liabilities.'+str(year),'operating_profit_and_loss.'+str(year),\n",
    "    'profit_and_loss_after_taxes.'+str(year),'staff_count.'+str(year),'financial_profit_and_loss.'+str(year)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the first five rows\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fill the missing value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fillna Strategy 1: Fill with the median value of previous years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2020 of previous five years (2015,2016,2017,2018,2019)\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2020\"]=df_clean[f\"{feature}.2020\"].fillna(df_clean[[f\"{feature}.2019\",f\"{feature}.2018\",f\"{feature}.2017\",f\"{feature}.2016\",f\"{feature}.2015\"]].median(axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missinf value again after the filling\n",
    "sum(df_clean[\"ebit.2020\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2019 of previous four years (2015,2016,2017,2018)\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2019\"]=df_clean[f\"{feature}.2019\"].fillna(df_clean[[f\"{feature}.2018\",f\"{feature}.2017\",f\"{feature}.2016\",f\"{feature}.2015\"]].median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missinf value again after the filling\n",
    "sum(df_clean[\"ebit.2019\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2018 of previous 3 years (2015,2016,2017)\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2018\"]=df_clean[f\"{feature}.2018\"].fillna(df_clean[[f\"{feature}.2017\",f\"{feature}.2016\",f\"{feature}.2015\"]].median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2017 of previous 2 years (2015,2016)\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2017\"]=df_clean[f\"{feature}.2017\"].fillna(df_clean[[f\"{feature}.2016\",f\"{feature}.2015\"]].median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2016 of previous 1 years (2015)\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2016\"]=df_clean[f\"{feature}.2016\"].fillna(df_clean[[f\"{feature}.2015\"]].median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan value in year 2015 of median value of all 6 years\n",
    "features=['ebit','total_assets','staff_costs','revenue','net_added_value']\n",
    "for feature in features:\n",
    "    df_clean[f\"{feature}.2015\"]=df_clean[f\"{feature}.2015\"].fillna(df_clean[[f\"{feature}.2020\",f\"{feature}.2019\",f\"{feature}.2018\",f\"{feature}.2017\",f\"{feature}.2016\",f\"{feature}.2015\"]].median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing value of whole dataset after the filling\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fillna Stategy 2: Fill in the missing value of median based on company_category, province, and nace_code and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataset\n",
    "df_melted = pd.melt(df_clean, id_vars=['vat_number','company_category','province','nace_code'])\n",
    "df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the financial part with year\n",
    "df_melted[['financial_data','year']]=df_melted.variable.str.split('.',expand=True)\n",
    "df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted.drop(columns=['variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataset\n",
    "df_transform=df_melted.pivot(index=['vat_number','company_category','province','nace_code','year'],columns=['financial_data'], values='value')\n",
    "#rename the revenue to current_revenue\n",
    "df_transform=df_transform.rename(columns={'revenue':'current_revenue'})\n",
    "df_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get information of the whole dataset\n",
    "df_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add next_year_revenue column\n",
    "df_transform[f\"next_year_revenue\"] = df_transform.groupby('vat_number')['current_revenue'].shift(-1)\n",
    "df_transform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "df_transform=df_transform.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first two digitals of nace_code, to know the companies' activities\n",
    "df_transform['nace_code_section'] =df_transform['nace_code'].astype(str).str[:2]\n",
    "#reorder the column\n",
    "df_transform = df_transform[['vat_number','company_category','province','nace_code','nace_code_section',\n",
    "                            'year','ebit','net_added_value','staff_costs','total_assets','current_revenue','next_year_revenue']]\n",
    "df_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select datafram which next_year_revenue is not nan\n",
    "df_transform=df_transform[df_transform['next_year_revenue'].notna()]\n",
    "df_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the median value based on company category province, nace_code and year\n",
    "df_median=df_transform.groupby(['company_category', 'province','nace_code_section','year'])['ebit','net_added_value', 'staff_costs','total_assets','current_revenue'].median()\n",
    "df_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median.to_csv('/Users/yihuiwang/Documents/BeCode/My_project/Revenue Forcasting/asset/median.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing value with median value based on company category, province, nace section and year\n",
    "df_transform[['ebit','net_added_value', 'staff_costs','total_assets','current_revenue']] = df_transform.groupby(['company_category', 'province','nace_code_section','year'])['ebit','net_added_value', 'staff_costs','total_assets','current_revenue'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nan value after filling\n",
    "df_transform.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7:Finalize the training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many 0 in staff_costs\n",
    "df_transform.loc[(df_transform['staff_costs'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing value\n",
    "df_transform.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop current_revenue feature\n",
    "train_df = df_transform.drop(columns=['current_revenue'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows, if all the features are missing\n",
    "train_df= train_df.dropna(how='all',\n",
    "                    subset=['ebit','net_added_value','staff_costs','total_assets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing value\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the missing value in staff_costs\n",
    "train_df=train_df.dropna(subset = ['staff_costs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing value again after drop\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check where staff_cost is 0\n",
    "train_df.loc[(train_df['staff_costs'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop staff_costs, as there are too many 0 in that feature\n",
    "#also drop the unnecessay column for train the model\n",
    "train_df=train_df.drop(columns=['staff_costs','vat_number','company_category','province','nace_code','nace_code_section','year'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the train data to csv file\n",
    "train_df.to_csv('/Users/yihuiwang/Documents/BeCode/My_project/Revenue Forcasting/asset/final_data_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
